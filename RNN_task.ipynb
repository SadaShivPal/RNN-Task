{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "f4qvjEG_y9Ub",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "Jm1-W5d6y9Uf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VKCyS7XZy9Ut",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Our data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "id": "mLV2PYrMy9Uv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "start_token = \" \"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token+name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8sdNSxDNy9U3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print ('n samples = ',len(names))\n",
        "for x in names[::1000]:\n",
        "    print (x)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ed97NyK3y9U-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len,names))\n",
        "print(\"max length =\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len,names)),bins=25);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06Uu2mISy9VE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "id": "tTA8dbQTy9VG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#all unique characters go here\n",
        "\n",
        "chars = set()\n",
        "for name in names:\n",
        "    chars.update([char for char in name])\n",
        "\n",
        "tokens = list(chars)\n",
        "\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens = ',n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9Sgm0Zgy9VJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign "
      ]
    },
    {
      "metadata": {
        "id": "RKJtE6oey9VM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {}\n",
        "for index, token in enumerate(tokens):\n",
        "    token_to_id[token] = index\n",
        "#token_to_id = ###YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35KmYhD6y9VS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FsEQs-mKy9Va",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names,max_len=None,pad=0,dtype='int32'):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len,names))\n",
        "    names_ix = np.zeros([len(names),max_len],dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get,names[i]))\n",
        "        names_ix[i,:len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FIuRo85Iy9Vm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Example: cast 4 random names to matrices, pad with zeros\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]).T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ovJTcnmPy9Vs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/IAmSuyogJadhav/AML-Specialization-Exercises-Coursera/blob/master/Intro%20to%20Deep%20Learning/Week%205/rnn.png?raw=1\" width=480>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme"
      ]
    },
    {
      "metadata": {
        "id": "UVe89wJTy9Vs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Concatenate,Dense,Embedding\n",
        "\n",
        "rnn_num_units = 64\n",
        "embedding_size = 16\n",
        "\n",
        "#Let's create layers for our recurrent network\n",
        "#Note: we create layers but we don't \"apply\" them yet\n",
        "embed_x = Embedding(n_tokens,embedding_size) # an embedding layer that converts character ids into embeddings\n",
        "\n",
        "\n",
        "#a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='relu')\n",
        "\n",
        "#a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')\n",
        "\n",
        "#Note: please either set the correct activation to Dense or write it manually in rnn_one_step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mVM9pgRYy9Vx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces next state and output\n",
        "    given prev input and previous state.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    #convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t,[-1,1]))[:,0]\n",
        "    \n",
        "    #concatenate x embedding and previous h state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
        "    \n",
        "    #compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    #get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas,h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SAOJlNHyy9V2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN loop\n",
        "\n",
        "Once rnn_one_step is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "id": "QsaWHNLly9V3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder('int32',(MAX_LENGTH,None))\n",
        "batch_size = tf.shape(input_sequence)[1]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size,rnn_num_units]) #initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[t]\n",
        "    probas_next,h_next = rnn_one_step(x_t,h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "predicted_probas = tf.stack(predicted_probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rxq-tkTny9V7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "id": "Kn0Mswq7y9V8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions_matrix = tf.reshape(predicted_probas[:-1],[-1,len(tokens)])\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[1:],[-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DukKZhUVy9WA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*tf.log(tf.clip_by_value(predictions_matrix,1e-8,1.0)), reduction_indices=[1]))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5avy_Uoy9WD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The training loop"
      ]
    },
    {
      "metadata": {
        "id": "F2DisT5-y9WH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "s = keras.backend.get_session()\n",
        "s.run(tf.global_variables_initializer())\n",
        "history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bt45s08Dy9WR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names,32),max_len=MAX_LENGTH)\n",
        "    loss_i,_ = s.run([loss,optimize],{input_sequence:batch})\n",
        "    \n",
        "    \n",
        "    history.append(loss_i)\n",
        "    if (i+1)%100==0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5HbtEwTy9WX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "id": "MYZmX6QFy9WY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder('int32',(None,))\n",
        "h_t = tf.Variable(np.zeros([1,rnn_num_units],'float32'))\n",
        "\n",
        "next_probs,next_h = rnn_one_step(x_t,h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SkgGZLgvy9Wb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=' ',max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "        \n",
        "    parameters:\n",
        "        The phrase is set using the variable seed_phrase\n",
        "        The optional input \"N\" is used to set the number of characters of text to predict.     \n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t,h_t.initial_value))\n",
        "    \n",
        "    #feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t,next_h),{x_t:[ix]})\n",
        "    \n",
        "    #start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs,tf.assign(h_t,next_h)],{x_t:[x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens,p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGSwNhUey9Wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNiN0nkIy9Wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for _ in range(50):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvYDzGKby9Wn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Submit to coursera"
      ]
    },
    {
      "metadata": {
        "id": "qQRuMImEy9Wo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in range(25)]\n",
        "submission = (history,samples)\n",
        "submit_char_rnn(submission, \"\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbGCZFxLy9Wr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Try it out!\n",
        "\n",
        "__Disclaimer:__ This assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* Ikea catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Levo8IO4y9Wt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from keras, there's also a friendly tensorflow API for recurrent neural nets. It's based around the symbolic loop function (aka [scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures."
      ]
    },
    {
      "metadata": {
        "id": "s7i88abhy9Wu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self,input,state):\n",
        "        return rnn_one_step(input[:,0],state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "\n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder('int32',(None,None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell,input_sequence[:,:,None],\n",
        "                                                 time_major=True,dtype='float32')\n",
        "\n",
        "print (predicted_probas.eval({input_sequence:to_matrix(names[:10],max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tGvuOsly9Wy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use the all the pre-implemented RNN cells:"
      ]
    },
    {
      "metadata": {
        "id": "Lv9laYYmy9Wz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell)+dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print (obj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4jJPqrFy9W3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder('int32',(None,None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence,last_state = tf.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
        "\n",
        "print('LSTM visible states[time,batch,unit]:', state_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}